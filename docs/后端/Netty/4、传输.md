---
typora-copy-images-to: ../../public
typora-root-url: /Volumes/硬盘/Code/docs/docs/public
---

<script setup>
	import TableCaption from '../../../components/TableCaption.vue';
</script>



流经网络的数据总是具有相同的类型: **字节**。 这些字节是如何流动的主要取决于我们所说的网络传输—一个帮助我们抽象底层数据传输机制的概念。 用户并不关心这些细节; 他们只想确保他们的字节被可靠地发送和接收。

## 案例研究：传输迁移

### 不通过 Netty 使用 OIO 和 NIO

我们将介绍仅使用了 JDK API 的应用程序的阻塞(OIO)版本和异步(NIO)版本。

::: code-group

```java [未使用 Netty 的阻塞网络编程]
public class PlainOioServer {
    public void serve(int port) throws IOException {
        final ServerSocket socket = new ServerSocket(port);
        try {
            for (; ; ) {
                final Socket clientSocket = socket.accept();
                System.out.println("Accepted connection from " + clientSocket);
                new Thread(new Runnable() {
                    @Override
                    public void run() {
                        OutputStream out;
                        try {
                            out = clientSocket.getOutputStream();
                            out.write("Hi!\r\n".getBytes(Charset.forName("UTF-8")));
                            out.flush();
                            clientSocket.close();
                        } catch (IOException e) {
                            e.printStackTrace();
                        } finally {
                            try {
                                clientSocket.close();
                            } catch (IOException ex) {
                            }
                        }
                    }
                }).start();
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
```

```java [未使用 Netty 的异步网络编程]
public class PlainNioServer {
    public void serve(int port) throws IOException {
        ServerSocketChannel serverChannel = ServerSocketChannel.open();
        serverChannel.configureBlocking(false);
        ServerSocket ssocket = serverChannel.socket();
        InetSocketAddress address = new InetSocketAddress(port);
        ssocket.bind(address);
        Selector selector = Selector.open();
        serverChannel.register(selector, SelectionKey.OP_ACCEPT);
        final ByteBuffer msg = ByteBuffer.wrap("Hi!\r\n".getBytes());
        for (; ; ) {
            try {
                selector.select();
            } catch (IOException ex) {
                ex.printStackTrace();                 // handle exception                 
                break;
            }
            Set<SelectionKey> readyKeys = selector.selectedKeys();
            Iterator<SelectionKey> iterator = readyKeys.iterator();
            while (iterator.hasNext()) {
                SelectionKey key = iterator.next();
                iterator.remove();
                try {
                    if (key.isAcceptable()) {
                        ServerSocketChannel server = (ServerSocketChannel) key.channel();
                        SocketChannel client = server.accept();
                        client.configureBlocking(false);
                        client.register(selector, SelectionKey.OP_WRITE | SelectionKey.OP_READ, msg.duplicate());
                        System.out.println("Accepted connection from " + client);
                    }
                    if (key.isWritable()) {
                        SocketChannel client = (SocketChannel) key.channel();
                        ByteBuffer buffer = (ByteBuffer) key.attachment();
                        while (buffer.hasRemaining()) {
                            if (client.write(buffer) == 0) {
                                break;
                            }
                        }
                        client.close();
                    }
                } catch (IOException ex) {
                    key.cancel();
                    try {
                        key.channel().close();
                    } catch (IOException cex) {                         // ignore on close                     
                    }
                }
            }
        }
    }
}
```

:::

阻塞网络编程代码完全可以处理中等数量的并发客户端。 但是随着应用程序变得流行起来, 你会发现它并不能很好地伸缩到支撑成千上万的并发连入连接。 你决定改用异步网络编程, 但是很快就发现异步 API 是完全不同的,以至于现在你不得不重写你的应用程序。

### 通过 Netty 使用 OIO 和 NIO



::: code-group

```java [使用 Netty 的阻塞网络处理]
public class NettyOioServer {
    public void server(int port) throws Exception {
        final ByteBuf buf = Unpooled.unreleasableBuffer(Unpooled.copiedBuffer("Hi!\r\n", Charset.forName("UTF-8")));
        EventLoopGroup group = new OioEventLoopGroup();
        try {
            ServerBootstrap b = new ServerBootstrap();
            b.group(group).channel(OioServerSocketChannel.class).localAddress(new InetSocketAddress(port)).childHandler(new ChannelInitializer<SocketChannel>() {
                @Override
                public void initChannel(SocketChannel ch) throws Exception {
                    ch.pipeline().addLast(new ChannelInboundHandlerAdapter() {
                        @Override
                        public void channelActive(ChannelHandlerContext ctx) throws Exception {
                            ctx.writeAndFlush(buf.duplicate()).addListener(ChannelFutureListener.CLOSE);
                        }
                    });
                }
            });
            ChannelFuture f = b.bind().sync();
            f.channel().closeFuture().sync();
        } finally {
            group.shutdownGracefully().sync();
        }
    }
}
```

```java [使用 Netty 的异步网络处理]
public class NettyNioServer {
    public void server(int port) throws Exception {
        final ByteBuf buf = Unpooled.copiedBuffer("Hi!\r\n", Charset.forName("UTF-8"));
        EventLoopGroup group = new NioEventLoopGroup();
        try {
            ServerBootstrap b = new ServerBootstrap();
            b.group(group).channel(NioServerSocketChannel.class).localAddress(new InetSocketAddress(port)).childHandler(new ChannelInitializer<SocketChannel>() {
                @Override
                public void initChannel(SocketChannel ch) throws Exception {
                    ch.pipeline().addLast(new ChannelInboundHandlerAdapter() {
                        @Override
                        public void channelActive(ChannelHandlerContext ctx) throws Exception {
                            ctx.writeAndFlush(buf.duplicate()).addListener(ChannelFutureListener.CLOSE);
                        }
                    });
                }
            });
            ChannelFuture f = b.bind().sync();
            f.channel().closeFuture().sync();
        } finally {
            group.shutdownGracefully().sync();
        }
    }
}
```

:::

因为 Netty 为每种传输的实现都暴露了相同的 API,所以无论选用哪一种传输的实现,你的代码都仍然几乎不受影响。在所有的情况下,传输的实现都依赖于 `Channel`、`ChannelPipeline` 和 `ChannelHandler`。

## 传输API

传输 API 的核心是 interface Channel,它被用于所有的 I/O 操作。Channel 类的层次结构如图 4-1 所示。

![Netty实战_page_67_1](/Netty实战_page_67_1.png)

如图所示,每个 `Channel` 都将会被分配一个 `ChannelPipeline` 和 `ChannelConfig`。
`ChannelConfig` 包含了该 `Channel` 的所有配置设置,并且支持热更新。由于特定的传输可能具有独特的设置, 所以它可能会实现一个`ChannelConfig`的子类型。
(请参考ChannelConfig 实现对应的 Javadoc。 )

由于 Channel 是独一无二的,所以为了保证顺序将 `Channel` 声明为` `java.lang.` 
Comparable` 的一个子接口。因此,如果两个不同的 `Channel` 实例都返回了相同的散列码,那么 `AbstractChannel` 中的 `compareTo()`方法的实现将会抛出一个 `Error`。

`ChannelPipeline` 持有所有将应用于入站和出站数据以及事件的 `ChannelHandler` 实例,这些 `ChannelHandler` 实现了应用程序用于处理状态变化以及数据处理的逻辑。

`ChannelHandler` 的典型用途包括: 

*   将数据从一种格式转换为另一种格式;
*   提供异常的通知;
*   提供 `Channel` 变为活动的或者非活动的通知;
*   提供当 `Channel` 注册到 `EventLoop` 或者从 `EventLoop` 注销时的通知;
*   提供有关用户自定义事件的通知。

::: tip 拦截过滤器

ChannelPipeline 实现了一种常见的设计模式—拦截过滤器(Intercepting Filter) 。UNIX 管道是另外一个熟悉的例子:多个命令被链接在一起,其中一个命令的输出端将连接到命令行中下一个命令的输入端。

:::

你也可以根据需要通过添加或者移除ChannelHandler实例来修改ChannelPipeline。通过利用Netty的这项能力可以构建出高度灵活的应用程序。

除了访问所分配的 ChannelPipeline 和 ChannelConfig 之外,也可以利用 Channel 的其他方法,其中最重要的列举在下表中。

<TableCaption :title="'Channel的方法'" />

|    方法名     |                             描述                             |
| :-----------: | :----------------------------------------------------------: |
|   eventLoop   |                 返回分配给Channel的EventLoop                 |
|   pipeline    |              返回分配给Channel的ChannelPipeline              |
|   isActive    | 如果Channel是活动的, 则返回true。 活动的意义可能依赖于底层的传输。 例如, 一个Socket传输一旦连接到了远程节点便是活动的, 而一个Datagram传输一旦被打开便是活动的 |
| localAddress  |                   返回本地的SokcetAddress                    |
| remoteAddress |                   返回远程的SocketAddress                    |
|     write     | 将数据写到远程节点。这个数据将被传递给 ChannelPipeline,并且排队直到它被冲刷 |
|     flush     |         将之前已写的数据冲刷到底层传输,如一个Socket          |
| writeAndFlush |      一个简便的方法,等同于调用write()并接着调用flush()       |

考虑一下写数据并将其冲刷到远程节点这样的常规任务。代码清单 4-5 演示了使用Channel.writeAndFlush()来实现这一目的。

::: code-group

```java [代码清单 4-5]
Channel channel = ... 
ByteBuf buf = Unpooled.copiedBuffer("your data", CharsetUtil.UTF_8); 
ChannelFuture cf = channel.writeAndFlush(buf);  
cf.addListener(new ChannelFutureListener() {       
	@Override     
    public void operationComplete(ChannelFuture future) {         
        if (future.isSuccess()) {
            System.out.println("Write successful");         
        } else {
            System.err.println("Write error");       
            future.cause().printStackTrace();         
        }     
    } 
});
```

:::

Netty 的 `Channel` 实现是线程安全的,因此你可以存储一个到 `Channel` 的引用,并且每当你需要向远程节点写数据时,都可以使用它,即使当时许多线程都在使用它。代码清单 4-6 展示了一个多线程写数据的简单例子。需要注意的是,消息将会被保证按顺序发送。

::: code-group

```java [代码清单 4-6]
final Channel channel = ... 
final ByteBuf buf = Unpooled.copiedBuffer("your data",CharsetUtil.UTF_8).retain();  
Runnable writer = new Runnable() {        
    @Override     
    public void run() {         
        channel.writeAndFlush(buf.duplicate());     
    } 
}; 
Executor executor = Executors.newCachedThreadPool();   
// write in one thread 
executor.execute(writer);   
// write in another thread 
executor.execute(writer);   ...
```

:::

## 内置的传输

Netty 内置了一些可开箱即用的传输。因为并不是它们所有的传输都支持每一种协议,所以你必须选择一个和你的应用程序所使用的协议相容的传输。

<TableCaption :title="'Netty 提供的传输'" />

| 名    称  | 包                          | 描述                                                         |
| --------- | --------------------------- | ------------------------------------------------------------ |
| NIO       | io.netty.channel.socket.nio | 使用 java.nio.channels 包作为基础——基于选择器的方式          |
| Epoll[^1] | io.netty.channel.epoll      | 由 JNI 驱动的epoll()和非阻塞 IO。这个传输支持只有在Linux上可用的多种特性, 如SO_REUSEPORT, 比 NIO 传输更快,而且是完全非阻塞的 |
| OIO       | io.netty.channel.socket.oio | 使用java.net包作为基础——使用阻塞流                           |
| Local     | io.netty.channel.local      | 可以在 VM 内部通过管道进行通信的本地传输                     |
| Embedded  | io.netty.channel.embedded   | Embedded 传输, 允许使用`ChannelHandler`而又不需要一个真正的基于网络的传输。这在测试你的`ChannelHandler`实现时非常有用 |

#### NIO——非阻塞 I/O

NIO 提供了一个所有 I/O 操作的<u>全异步</u>的实现。 它利用了自 NIO 子系统被引入 JDK 1.4 时便可用的基于选择器的 API。 
<u>选择器背后的基本概念是充当一个注册表,在那里你将可以请求在 Channel 的状态发生变化时得到通知</u>。可能的状态变化有:

*   新的 Channel 已被接受并且就绪;
*   Channel 连接已经完成;
*   Channel 有已经就绪的可供读取的数据;
*   Channel 可用于写数据。

选择器运行在一个检查状态变化并对其做出相应响应的线程上, 在应用程序对状态的改变做出响应之后,选择器将会被重置,并将重复这个过程。

表 4-3 中的常量值代表了由class java.nio.channels.SelectionKey定义的位模式。
这些位模式可以组合起来定义一组应用程序正在请求通知的状态变化集。

<TableCaption :title="'表 4-3  选择操作的位模式'" />

|    名称    |                             描述                             |
| :--------: | :----------------------------------------------------------: |
| OP_ACCEPT  |           请求在接受新连接并创建Channel时获得通知            |
| OP_CONNECT |                 请求在建立一个连接时获得通知                 |
|  OP_READ   |       请求当数据已经就绪,可以从Channel中读取时获得通知       |
|  OP_WRITE  | 请求当可以向Channel中写更多的数据时获得通知。这处理了套接字缓冲区被完全填满时的情况, 这种情况通常发生在数据的发送速度比远程节点可处理的速度更快的时候 |

对于所有 Netty 的传输实现都共有的用户级别 API 完全地隐藏了这些 NIO 的内部细节。
图 4-2 展示了该处理流程

![Netty实战_page_71_1](/Netty实战_page_71_1.png)

::: tip 零拷贝

零拷贝(zero-copy)是一种目前只有在使用 NIO 和 Epoll 传输时才可使用的特性。它使你可以快速高效地将数据从文件系统移动到网络接口,而不需要将其从内核空间复制到用户空间,其在像 FTP 或者HTTP 这样的协议中可以显著地提升性能。但是,并不是所有的操作系统都支持这一特性。特别地,它对于实现了数据加密或者压缩的文件系统是不可用的——只能传输文件的原始内容。反过来说,传输已被加密的文件则不是问题。

:::

#### Epoll—用于 Linux 的本地非阻塞传输

正如我们之前所说的,Netty 的 NIO 传输基于 Java 提供的异步/非阻塞网络编程的通用抽象。
虽然这保证了 Netty 的非阻塞 API 可以在任何平台上使用,但<u>它也包含了相应的限制</u>,因为 JDK 为了在所有系统上提供相同的功能,必须做出妥协。 
Linux作为高性能网络编程的平台,其重要性与日俱增,这催生了大量先进特性的开发,其中包括<u>epoll——一个高度可扩展的I/O事件通知特性</u>。这个API自Linux内核版本 2.5.44(2002)被引入,提供了比旧的POSIX select和poll系统调用更好的性能[^2],同时现在也是Linux上非阻塞网络编程的事实标准。Linux JDK NIO API使用了这些epoll调用。

Netty为Linux提供了一组NIO API,其以一种和它本身的设计更加一致的方式使用epoll,并且以一种更加轻量的方式使用中断。如果你的应用程序旨在运行于Linux系统,那么请考虑利用这个版本的传输;你将发现在高负载下它的性能要优于JDK的NIO实现。

这个传输的语义与在图 4-2 所示的完全相同,而且它的用法也是简单直接的。相关示例参照代码清单 4-4。如果要在那个代码清单中使用 epoll 替代 NIO,只需要将 `NioEventLoopGroup` 替 换 为 `EpollEventLoopGroup`, 并 且 将 `NioServerSocketChannel.class` 替 换 为`EpollServerSocketChannel.class` 即可

#### OIO—旧的阻塞 I/O

Netty 的 OIO 传输实现代表了一种折中:它可以通过常规的传输 API 使用,但是由于它是建立在 java.net 包的阻塞实现之上的,所以它不是异步的。但是,它仍然非常适合于某些用途。 
例如,你可能需要移植使用了一些进行阻塞调用的库(如JDBC)的遗留代码,而将逻辑转换为非阻塞的可能也是不切实际的。相反,你可以在短期内使用Netty的OIO传输,然后再将你的代码移植到纯粹的异步传输上。

#### 用于 JVM 内部通信的 Local 传输

Netty 提供了一个 Local 传输,用于在<u>同一个 JVM</u> 中运行的客户端和服务器程序之间的异步通信。同样,这个传输也支持对于所有 Netty 传输实现都共同的 API。

在这个传输中,和服务器 Channel 相关联的 SocketAddress 并没有绑定物理网络地址; 相反,只要服务器还在运行,它就会被存储在注册表里,并在 Channel 关闭时注销。因为这个传输并不接受真正的网络流量,所以它并不能够和其他传输实现进行互操作。因此,客户端希望连接到(在同一个 JVM 中)使用了这个传输的服务器端时也必须使用它。除了这个限制,它的使用方式和其他的传输一模一样。

![Netty实战_page_73_1](/Netty实战_page_73_1.png)

#### Embedded 传输

Netty 提供了一种额外的传输,使得你可以将一组 ChannelHandler 作为帮助器类嵌入到其他的 ChannelHandler 内部。 通过这种方式, 你将可以扩展一个 ChannelHandler 的功能, 而又不需要修改其内部代码。 
不足为奇的是,Embedded 传输的关键是一个被称为 EmbeddedChannel 的具体的 Channel 实现。在第 9 章中,我们将详细地讨论如何使用这个类来为 ChannelHandler 的实现创建单元测试用例。

## 传输的用例

正如前面所提到的,并不是所有的传输都支持所有的核心协议,其可能会限制你的选择。表 4-4 展示了截止出版时的传输和其所支持的协议。

<TableCaption :title="'表 4-4  支持的传输和网络协议'"/>

| 传输            | TCP  | UDP  | SCTP[^*] | UDT  |
| --------------- | ---- | ---- | -------- | ---- |
| NIO             | X    | X    | X        | X    |
| Epoll(仅 Linux) | X    | X    | -        | -    |
| OIO             | X    | X    | X        | X    |

::: tip 在 Linux 上启用 SCTP

SCTP 需要内核的支持,并且需要安装用户库。 
例如,对于 Ubuntu,可以使用下面的命令:   

\# sudo apt-get install libsctp1  

对于 Fedora,可以使用 yum:   

\#sudo yum install kernel-modules-extra.x86_64 lksctp-tools.x86_64  

有关如何启用 SCTP 的详细信息,请参考你的 Linux 发行版的文档。

:::

虽然只有 SCTP 传输有这些特殊要求, 但是其他传输可能也有它们自己的配置选项需要考虑。
此外,如果只是为了支持更高的并发连接数,服务器平台可能需要配置得和客户端不一样。

这里是一些你很可能会遇到的用例。 

*   非阻塞代码库——如果你的代码库中没有阻塞调用 (或者你能够限制它们的范围) , 那么在 Linux 上使用 NIO 或者 epoll 始终是个好主意。虽然 NIO/epoll 旨在处理大量的并发连接,但是在处理较小数目的并发连接时,它也能很好地工作,尤其是考虑到它在连接之间共享线程的方式。 
*   阻塞代码库——正如我们已经指出的,如果你的代码库严重地依赖于阻塞 I/O,而且你的应用程序也有一个相应的设计,那么在你尝试将其直接转换为 Netty 的 NIO 传输时,你将可能会遇到和阻塞操作相关的问题。不要为此而重写你的代码,可以考虑分阶段迁移:先从OIO 开始, 等你的代码修改好之后, 再迁移到 NIO (或者使用 epoll, 如果你在使用 Linux) 。  
*   在同一个 JVM 内部的通信——在同一个 JVM 内部的通信, 不需要通过网络暴露服务, 是Local 传输的完美用例。 这将消除所有真实网络操作的开销, 同时仍然使用你的 Netty 代码库。如果随后需要通过网络暴露服务,那么你将只需要把传输改为 NIO 或者 OIO 即可。 
*   测试你的ChannelHandler实现——如果你想要为自己的ChannelHandler实现编写单元测试,那么请考虑使用 Embedded 传输。这既便于测试你的代码,而又不需要创建大量的模拟(mock)对象。你的类将仍然符合常规的 API 事件流,保证该ChannelHandler 在 和 真 实 的 传 输 一 起 使 用 时 能 够 正 确 地 工 作 。 你 将 在 第 9 章 中 发 现 关 于 测 试ChannelHandler 的更多信息。

<TableCaption :title="'表 4-5  应用程序的最佳传输'" />

| 应用程序的需求                 | 推荐的传输                     |
| ------------------------------ | ------------------------------ |
| 非阻塞代码库或者一个常规的起点 | NIO(或者在 Linux 上使用 epoll) |
| 阻塞代码库                     | OIO                            |
| 在同一个 JVM 内部的通信        | Local                          |
| 测试ChannelHandler的实现       | Embedded                       |



---

[^1]: 这个是Netty特有的实现,更加适配Netty现有的线程模型,具有更高的性能以及更低的垃圾回收压力,详见https://github.com/netty/netty/wiki/Native-transports
[^2]: 参见 Linux 手册页中的 epoll(4):http://linux.die.net/man/4/epoll。
[^*]: 参见 RFC 2960 中有关流控制传输协议(SCTP)的解释:www.ietf.org/rfc/rfc2960.txt。

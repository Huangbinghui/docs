---
typora-copy-images-to: ../../public
typora-root-url: /Volumes/硬盘/Code/docs/docs/public
---

## Droplr


### 起因

Droplr最初是个LAMP 应用程序[^1]。后来随着发展，需要完全重新考虑 Droplr 的基础设施。

在那时, Droplr 本身已经确立成为了一种工作的理念, 因此 2.0 版本的目标也是相当的标准: 

*   将单片的技术栈拆分为多个可横向扩展的组件;
*   添加冗余,以避免宕机;
*   为客户端创建一个简洁的 API;
*   使其全部运行在 HTTPS 上。

### 工作原理

Droplr 拥有一个非常简单的工作流:将一个文件拖动到应用程序的菜单栏图标,然后 Droplr 将会上传该文件。当上传完成之后,Droplr 将复制一个短 URL——也就是所谓的拖乐(drop) —到剪贴板。

就是这样。欢畅地、实时地分享。 
而在幕后,拖乐元数据将会被存储到数据库中(包括创建日期、名称以及下载次数等信息) , 而文件本身则被存储在 Amazon S3 上。

### 创造一个更加快速的上传体验

Droplr 的第一个版本的上传流程是相当地天真可爱: 

(1)接收上传; 

(2)上传到 S3; 

(3)如果是图片,则创建略缩图; 

(4)应答客户端应用程序。

 更加仔细地看看这个流程, 你很快便会发现在第 2 步和第 3 步上有两个瓶颈。 不管从客户端上传到我们的服务器有多快,在实际的上传完成之后,直到成功地接收到响应之间,对于拖乐的创建总是会有恼人的间隔—因为对应的文件仍然需要被上传到 S3 中,并为其生成略缩图。

文件越大,间隔的时间也越长。对于非常大的文件来说,连接(客户端和服务器之间)最终将会在等待来自服务器的响应时超时。由于这个严重的问题,当时Droplr只可以提供单个文件最大 32MB的上传能力。 

有两种截然不同的方案来减少上传时间。 

*   方案 A,乐观且看似更加简单(见图 14-1) :
    *   完整地接收文件; 
    *   将文件保存到本地的文件系统,并立即返回成功到客户端;
    *   计划在将来的某个时间点将其上传到 S3。
*   方案 B,安全但复杂(见图 14-2) :
    *   实时地(流式地)将从客户端上传的数据直接管道给 S3。

<div class='flex place-content-between items-center mx-20'>
    <div>
        ![图 14-1  方案 A,乐观且看似更加简单](/Netty实战_page_214_1.png)
    </div>
    <div>
        ![图 14-2  方案 B,安全但复杂](/Netty实战_page_214_2.png)
    </div>
</div>

#### 乐观且看似更加简单的方案

在收到文件之后便返回一个短 URL 创造了一个空想 (也可以将其称为隐式的契约) , 即该文件立即在该 URL 地址上可用。但是并不能够保证,上传的第二阶段(实际将文件推送到 S3)也将最终会成功,那么用户可能会得到一个坏掉的链接,其可能已经被张贴到了 Twitter 或者发送给了一个重要的客户。这是不可接受的,即使是每十万次上传也只会发生一次。 

我们当前的数据显示,我们的上传失败率略低于 0.01%(万分之一) ,绝大多数都是在上传实际完成之前,客户端和服务器之间的连接就超时了。 

我们也可以尝试通过在文件被最终推送到 S3 之前,从接收它的机器提供该文件的服务来绕开它,然而这种做法本身就是一堆麻烦:

*   如果在一批文件被完整地上传到 S3 之前, 机器出现了故障, 那么这些文件将会永久丢失;
*   也将会有跨集群的同步问题( “这个拖乐所对应的文件在哪里呢?” ) ;
*   将会需要额外的复杂的逻辑来处理各种边界情况,继而不断产生更多的边界情况; 

在思考过每种变通方案和其陷阱之后, 我很快认识到, 这是一个经典的九头蛇问题——对于每个砍下的头,它的位置上都会再长出两个头。

#### 安全但复杂的方案

另一个选项需要对整体过程进行底层的控制。从本质上说,我们必须要能够做到以下几点。

*   在接收客户端上传文件的同时,打开一个到 S3 的连接。
*   将从客户端连接上收到的数据管道给到 S3 的连接。 
*   缓冲并节流这两个连接:
    *   需要进行缓冲,以在客户端到服务器,以及服务器到 S3 这两个分支之间保持一条的稳定的流;
    *   需要进行节流,以防止当服务器到 S3 的分支上的速度变得慢于客户端到服务器的分支时,内存被消耗殆尽。 
*   当出现错误时,需要能够在两端进行彻底的回滚。 

看起来概念上很简单,但是它并不是你的通常的 Web 服务器能够提供的能力。尤其是当你考虑节流一个 TCP 连接时,你需要对它的套接字进行底层的访问。 

它同时也引入了一个新的挑战,其将最终塑造我们的终极架构:推迟略缩图的创建。 

这也意味着,无论该平台最终构建于哪种技术栈之上,它都必须要不仅能够提供一些基本的特性,如难以置信的性能和稳定性,而且在必要时还要能够提供操作底层(即字节级别的控制)的灵活性。

### 技术栈

当开始一个新的 Web 服务器项目时,最终你将会问自己: “好吧,这些酷小子们这段时间都在用什么框架呢?”我也是这样的。 

选择 Netty 并不是一件无需动脑的事; 我研究了大量的框架, 并谨记我认为的 3 个至关重要的要素。  
	(1)它必须是快速的。我可不打算用一个低性能的技术栈替换另一个低性能的技术栈。 
	(2)它必须能够伸缩。不管它是有 1 个连接还是 10 000 个连接,每个服务器实例都必须要能够保持吞吐量,并且随着时间推移不能出现崩溃或者内存泄露。 
	(3)它必须提供对底层数据的控制。字节级别的读取、TCP 拥塞控制等,这些都是难点。 

要素 1 和要素 2 基本上排除了任何非编译型的语言。 我是 Ruby 语言的拥趸, 并且热爱 Sinatra 和 Padrino 这样的轻量级框架,但是我知道我所追寻的性能是不可能通过这些构件块实现的。 

要素 2 本身就意味着:无论是什么样的解决方案,它都不能依赖于阻塞 I/O。看到了本书这里,你肯定已经明白为什么非阻塞 I/O 是唯一的选择了。 

要素 3 比较绕弯儿。 它意味着必须要在一个框架中找到完美的平衡, 它必须在提供了对于它所接收到的数据的底层控制的同时,也支持快速的开发,并且值得信赖。这便是语言、文档、社区以及其他的成功案例开始起作用的时候了。 

在那时我有一种强烈的感觉:Netty 便是我的首选武器。

#### 基本要素:服务器和流水线

服务器基本上只是一个ServerBootstrap, 其内置了NioServerSocketChannelFactory, 配置了几个常见的 ChannelHandler 以及在末尾的 HTTP RequestController, 如代码清单14-1 所示。

```java [代码清单 14-1  设置 ChannelPipeline]
pipelineFactory = new ChannelPipelineFactory() {
    @Override public ChannelPipeline getPipeline() throws Exception {
        ChannelPipeline pipeline = Channels.pipeline();
        pipeline.addLast("idleStateHandler", new IdleStateHandler(...));
        pipeline.addLast("httpServerCodec", new HttpServerCodec());
        pipeline.addLast("requestController", new RequestController(...));
        return pipeline;
    }
};
```

RequestController 是 ChannelPipeline 中唯一自定义的 Droplr 代码,同时也可能是整个Web 服务器中最复杂的部分。它的作用是处理初始请求的验证,并且如果一切都没问题,那么将会把请求路由到适当的请求处理器。对于每个已经建立的客户端连接,都会创建一个新的实例, 并且只要连接保持活动就一直存在。 
请求控制器负责: 

*   处理负载洪峰; 
*   HTTP ChannelPipeline 的管理;
*   设置请求处理的上下文;
*   派生新的请求处理器; 
*   向请求处理器供给数据; 
*   处理内部和外部的错误。

代码清单 14-2 给出的是 RequestController 相关部分的一个纲要。

```java [代码清单 14-2  RequestController]
public class RequestController extends IdleStateAwareChannelUpstreamHandler {
    @Override
    public void channelIdle(ChannelHandlerContext ctx, IdleStateEvent e) throws Exception {
        // Shut down connection to client and roll everything back. 
    }
    @Override
    public void channelConnected(ChannelHandlerContext ctx, ChannelStateEvent e) throws Exception {
        if (!acquireConnectionSlot()) {
            // Maximum number of allowed server connections reached,             
            // respond with 503 service unavailable             
            // and shutdown connection. 
        } else {
            // Set up the connection's request pipeline. 
        }
    }
    @Override
    public void messageReceived(ChannelHandlerContext ctx, MessageEvent e) throws Exception {
        if (isDone()) return;
        if (e.getMessage() instanceof HttpRequest) {
            handleHttpRequest((HttpRequest) e.getMessage()); // Droplr 的服务器请求验证的关键点
        } else if (e.getMessage() instanceof HttpChunk) {
            handleHttpChunk((HttpChunk) e.getMessage()); // 如果针对当前请求有一个活动的处理器, 并且它能够接受 HttpChunk 数据, 那么它将继续按HttpChunk 传递
        }
    }
}
```

如同本书之前所解释过的一样, 你应该永远不要在 Netty 的 I/O 线程上执行任何非 CPU 限定的代码——你将会从 Netty 偷取宝贵的资源,并因此影响到服务器的吞吐量。 

因此,HttpRequest 和 HttpChunk 都可以通过切换到另一个不同的线程,来将执行流程移交给请求处理器。当请求处理器不是 CPU 限定时,就会发生这样的情况,不管是因为它们访问了数据库,还是执行了不适合于本地内存或者 CPU 的逻辑。 

当发生线程切换时,所有的代码块都必须要以串行的方式执行;否则,我们就会冒风险,对于一次上传来说,在处理完了序列号为 n 的HttpChunk 之后,再处理序列号为 n - 1 的HttpChunk 必然会导致文件内容的损坏。 (我们可能会交错所上传的文件的字节布局。 )为了处理这种情况,我创建了一个自定义的线程池执行器, 其确保了所有共享了同一个通用标识符的任务都将以串行的方式被执行。  

从这里开始,这些数据(请求和 HttpChunk)便开始了在 Netty 和 Droplr 王国之外的冒险。  

我将简短地解释请求处理器是如何被构建的,以在 RequestController(其存在于 Netty 的领地)和这些处理器(存在于 Droplr 的领地)之间的桥梁上亮起一些光芒。谁知道呢,这也许将会帮助你架构你自己的服务器应用程序呢!

#### 请求处理器

请求处理器提供了 Droplr 的功能。它们是类似地址为/account 或者/drops 这样的 URI 背后的端点。它们是逻辑核心——服务器对于客户端请求的解释器。 

请求处理器的实现也是(Netty)框架实际上成为了 Droplr 的 API 服务器的地方。

#### 父接口

每个请求处理器,不管是直接的还是通过子类继承,都是 RequestHandler 接口的实现。  

其本质上,RequestHandler 接口表示了一个对于请求(HttpRequest 的实例)和分块(HttpChunk 的实例) 的无状态处理器。 它是一个非常简单的接口, 包含了一组方法以帮助请求控制器来执行以及/或者决定如何执行它的职责,例如: 

*   请求处理器是有状态的还是无状态的呢?它需要从某个原型克隆,还是原型本身就可以用来处理请求呢?
*   请求处理器是 CPU 限定的还是非 CPU 限定的呢?它可以在 Netty 的工作线程上执行, 还是需要在一个单独的线程池中执行呢? 
*   回滚当前的变更;
*   清理任何使用过的资源。 

这个接口(RequestHandler)就是RequestController对于相关动作的所有理解。 通过它非常清晰和简洁的接口, 该控制器可以和有状态的和无状态的、 CPU限定的和非CPU限定的 (或者这些性质的组合) 处理器以一种独立的并且实现无关的方式进行交互。

#### 处理器的实现

最简单的 RequestHandler 实现是 AbstractRequestHandler,它代表一个子类型的层次结构的根,在到达提供了所有 Droplr 的功能的实际处理器之前,它将变得愈发具体。最终, 它会到达有状态的实现 SimpleHandler,它在一个非 I/O 工作线程中执行,因此也不是 CPU 限定的。SimpleHandler 是快速实现那些执行读取 JSON 格式的数据、访问数据库,然后写出一些 JSON 的典型任务的端点的理想选择。

#### 上传请求处理器

上传请求处理器是整个 Droplr API 服务器的关键。 它是对于重塑 webserver 模块——服务器的框架化部分的设计的响应,也是到目前为止整个技术栈中最复杂、最优化的代码部分。 

在上传的过程中,服务器具有双重行为: 

*   在一边,它充当了正在上传文件的 API 客户端的服务器;
*   在另一边,它充当了 S3 的客户端,以推送它从 API 客户端接收的数据。 

为了充当客户端,服务器使用了一个同样使用Netty构建的HTTP客户端库[^2][^3]。这个异步的HTTP客户端库暴露了一组完美匹配该服务器的需求的接口。 它将开始执行一个HTTP请求, 并允许在数据变得可用时再供给给它,而这大大地降低了上传请求处理器的客户门面的复杂性。

### 性能

在服务器的初始版本完成之后,我运行了一批性能测试。结果简直就是让人兴奋不已。在不断地增加了难以置信的负载之后,我看到新的服务器的上传在峰值时相比于旧版本的 LAMP 技术栈的快了 10~12 倍(完全数量级的更快) ,而且它能够支撑超过 1000 倍的并发上传,总共将近 10k 的并发上传(而这一切都只是运行在一个单一的 EC2 大型实例之上) 。 

下面的这些因素促成了这一点。

*   它运行在一个调优的 JVM 中。 
*   它运行在一个高度调优的自定义技术栈中,是专为解决这个问题而创建的,而不是一个通用的 Web 框架。 
*   该自定义的技术栈通过 Netty 使用了 NIO(基于选择器的模型)构建,这意味着不同于每个客户端一个进程的 LAMP 技术栈,它可以扩展到上万甚至是几十万的并发连接。 
*   再也没有以两个单独的,先接收一个完整的文件,然后再将其上传到 S3,的步骤所带来的开销了。现在文件将直接流向 S3。 
*   因为服务器现在对文件进行了流式处理,所以: 
    *   它再也不会花时间在 I/O 操作上了,即将数据写入临时文件,并在稍后的第二阶段上传中读取它们;
    *   对于每个上传也将消耗更少的内存,这意味着可以进行更多的并行上传。 
*   略缩图生成变成了一个异步的后处理。

## Firebase

实时更新是现代应用程序中用户体验的一个组成部分。 随着用户期望这样的行为, 越来越多的应用程序都正在实时地向用户推送数据的变化。通过传统的 3 层架构很难实现实时的数据同步,其需要开发者管理他们自己的运维、服务器以及伸缩。通过维护到客户端的实时的、双向的通信,Firebase 提供了一种即时的直观体验,允许开发人员在几分钟之内跨越不同的客户端进行应用程序数据的同步—这一切都不需要任何的后端工作、服务器、运维或者伸缩。 

实现这种能力提出了一项艰难的技术挑战,而 Netty 则是用于在 Firebase 内构建用于所有网络通信的底层框架的最佳解决方案。这个案例研究概述了 Firebase 的架构,然后审查了 Firebase 使用 Netty 以支撑它的实时数据同步服务的 3 种方式: 

*   长轮询;
*   HTTP 1.1 keep-alive 和流水线化;
*   控制 SSL 处理器。

### 架构



### 长轮询



### KeepAlive和流水线优化



### 控制SslHanllder



## Urban AirShipAirShip

### 移动消息的基础知识



### 第三方递交



### 使用二进制协议的例子



### 直接面向设备的递交



### Netty擅长管理大量的并发连接



### Urban Airship小结



#### 内部RPC框架



#### 负载和性能测试



#### 同步协议的异步客户端





[^1]:一个典型的应用程序技术栈的首字母缩写;由 Linux、Apache Web Server、MySQL 以及 PHP 的首字母组成。
[^2]:你可以在 https://github.com/brunodecarvalho/http-client 找到这个 HTTP 客户端库
[^3]:上一个脚注中提到的这个 HTTP 客户端库已经废弃, 推荐 AsyncHttpClient (https://github.com/AsyncHttpClient/async-http-client)和 Akka-HTTP(https://github.com/akka/akka-http) ,它们都实现了相同的功能。
